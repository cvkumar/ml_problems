WHAT TO DO:
1) Run the clustering algorithms on the datasets and describe what you see. can choose your own measures of distance/similarity (will have to justify)
- K-means clustering
- Expectation Maximization
-2 (datasets) * 2(CA) = 4 Results

2) Apply the dimensionality reduction algorithms to the two datasets and describe what you see.
-PCA
-ICA
-Randomized Projections (RCA)
-Any other feature selection algorithm you desire
-4 (DR) * 2 (Datasets) => 8 Results


3) Reproduce your clustering experiments, but on the data after you've run dimensionality reduction on it.
Yes, thatâ€™s 16 combinations of datasets, dimensionality reduction, and clustering method.
You should look at all of them, but focus on the more interesting findings in your report.
- Run dimensionality reduction algorithms on the data, then run your clustering algorithm again on the result
- 2 (datasets) * 2 (Clustering) * 4 (Dimensionality) = 16 results
- Focus on interesting findings


- 2 (datasets) * 2 (clustering) * 5 (plot per metric) = 20 PLOTS

Weather, EM
SILHOUETTE SCORE: original, ica, pca, grp, rf

Weather, K MEANS
SSE VS Num CLUSTERS: original, ica, pca, grp, rf

AFRICA, EM
SILHOUETTE SCORE: original, ica, pca, grp, rf

AFRICA, K MEANS
SSE: original, ica, pca, grp, rf

4) Apply the dimensionality reduction algorithms to one of your datasets from assignment #1
(if you've reused the datasets from assignment #1 to do experiments 1-3 above then you've already done this)
and rerun your neural network learner on the newly projected data.
-One dataset, run 4 DR algorithms on it, run neural network on result
-1 (dataset) * 4 (DRs) * 1 (Neural Network) => 4 NN

5) Apply the clustering algorithms to the same dataset to which you just applied the dimensionality reduction algorithms
(you've probably already done this), treating the clusters as if they were new features.
In other words, treat the clustering algorithms as if they were dimensionality reduction algorithms. Again, rerun your neural network learner on the newly projected data.
-Run DR algorithms on dataset, then run clustering algorithms on result, then run neural network on that!
-1 (dataset) * 2 (Clustering algorithms) * 1 (Neural Network) => 2 NN



TURN IN:
-A file named README.txt that contains instructions for running your code
-Code (link only in the README.txt)
-Up to 10 pages of analysis.




ANALYSIS SHOULD CONTAIN:
-Reminder on why problems are interesting

-explanations of your methods: for example, how did you choose k?

-description of the kind of clusters that you got.

-analyses of your results. Why did you get the clusters you did?
Do they make "sense"? If you used data that already had labels (for example data from a classification problem from assignment #1) did the clusters line up with the labels?
Do they otherwise line up naturally? Why or why not?
Compare and contrast the different algorithms.
What sort of changes might you make to each of those algorithms to improve performance?
How much performance was due to the problems you chose?
Take care to justify your analysis with data explicitly.

-Can you describe how the data look in the new spaces you created with the various algorithms?
For PCA, what is the distribution of eigenvalues? For ICA, how kurtotic are the distributions?
Do the projection axes for ICA seem to capture anything "meaningful"?
Assuming you only generate k projections (i.e., you do dimensionality reduction), how well is the data reconstructed by the randomized projections?
PCA? How much variation did you get when you re-ran your RP (RCA) several times (I know I don't have to mention that you might want to run RP many times to see what happens, but I hope you forgive me)?

When you reproduced your clustering experiments on the datasets projected onto the new spaces created by ICA, PCA, and RP, did you get the same clusters as before? Different clusters? Why? Why not?

-When you re-ran your neural network algorithms were there any differences in performance? Speed? Anything at all?

-Don't always have to graph things

